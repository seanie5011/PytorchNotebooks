{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8f49503-d3fc-4af2-8f55-032f38ef7ada",
   "metadata": {},
   "source": [
    "# Learning Pytorch: MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db35a14-2033-46fa-9afc-39cfe7d1e830",
   "metadata": {},
   "source": [
    "In this notebook we will go through a complete introduction to Pytorch, using the MNIST dataset as an example.\n",
    "\n",
    "*This follows the tutorial by NeuralNine: https://www.youtube.com/watch?v=vBlO87ZAiiw&list=WL&index=5&t=161s&ab_channel=NeuralNine*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9923997d-6837-4fb5-889a-c704d95c3985",
   "metadata": {},
   "source": [
    "## The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec5c76c-c420-4194-8a5e-f9975ed2ae12",
   "metadata": {},
   "source": [
    "A tutorial by the pytorch community on the FashionMNIST dataset: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf67ca9-c410-4f1d-a7ec-60dba66be51b",
   "metadata": {},
   "source": [
    "### Importing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7f3949-f7ef-46f4-86e5-5e318962f0c3",
   "metadata": {},
   "source": [
    "The torchvision package consists of popular datasets, model architectures, and common image transformations for computer vision. We import certain datasets and transform them to tensors by using the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b45f5f04-1504-4b0b-821f-8cc09fa386f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b79af8-df19-4384-b19d-f0704cc2204b",
   "metadata": {},
   "source": [
    "We use the `train` parameter to determine whether we are looking at training or testing data. Setting `download` to false means it would look for the dataset in local storage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8373f496-4943-4821-8e96-4343b8834a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    transform=ToTensor(),\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    transform=ToTensor(),\n",
    "    download=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb7be2a-9c9b-4495-84be-f59a9d7100f7",
   "metadata": {},
   "source": [
    "Let's look at some details of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb1636d6-9fe1-4636-bf8b-90b223019ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dd1f89-0fb9-4222-84a4-f289a187fdc2",
   "metadata": {},
   "source": [
    "The `.data` attribute is the pixel images of our digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce351e93-bacc-41f8-aef7-0a503c1c1d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01380fab-743a-4ffd-8fb2-cc12e7b3bc1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.shape  # note you can also call train_data.data.size() for the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e333f1e-ef5d-4157-8ce1-053aee136c79",
   "metadata": {},
   "source": [
    "And the `.targets` attribute are the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ea38da9-55d7-4237-96e3-d93bf076b1e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4,  ..., 5, 6, 8])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69a2ab49-13a0-4745-9293-902547a841a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc319ed-3f52-4030-8bac-162c6b34a7b9",
   "metadata": {},
   "source": [
    "Likewise for the testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39a430d8-8fbb-49b2-b2ca-71c6eda01469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c2659bd-fd73-4caa-964e-e62a8a8852f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 28, 28])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "899dbb7a-0b34-44ad-a9a2-65a158009a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f2ea37-7711-48de-bba9-df9dd248ceb1",
   "metadata": {},
   "source": [
    "Let's visualise some of these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2698421b-31a0-4804-9e82-135b7e06412b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(train_data), size=(1,)).item()\n",
    "    img, label = train_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(label)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c7ced1-8614-4eae-99bd-76fbd1276f80",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773c24dd-8b3f-45da-a991-98ffceb55af8",
   "metadata": {},
   "source": [
    "The dataset retrieves our dataset's features and labels one sample at a time. While training a model, we typically want to pass samples in \"minibatches\", `DataLoader` is an iterable that allows us to do this:le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9055f9a0-d595-4586-b942-ac85a53093bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x1c5dac9c9a0>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x1c5dac63670>}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loaders = {\n",
    "    \"train\": DataLoader(\n",
    "        train_data,\n",
    "        batch_size=100,\n",
    "        shuffle=True,\n",
    "        num_workers=1,  # how many subprocesses to use for data loading\n",
    "    ),\n",
    "    \"test\": DataLoader(\n",
    "        test_data,\n",
    "        batch_size=100,\n",
    "        shuffle=True,\n",
    "        num_workers=1,\n",
    "    ),\n",
    "}\n",
    "loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2376e3c7-86bf-44f7-a333-eacdd92c7335",
   "metadata": {},
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d6f226-c1fd-4f26-a841-2ac5fdb6c5b1",
   "metadata": {},
   "source": [
    "We need the following to create our Neural Network model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec840144-d540-4519-b41e-fc706351447b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a433c636-1d86-457a-adac-609a34eae365",
   "metadata": {},
   "source": [
    "The model we are going to create is a Convolutional Neural Network (CNN), consisting of two convolutional layers, a dropout layer, and two dense layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ee55ad5-5c51-40a5-902e-165f36effbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Where we define our model.\n",
    "        \"\"\"\n",
    "        super(CNN, self).__init__()  # inherit from module\n",
    "\n",
    "        # convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)  # 1 in, 10 out\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)  # 10 in, 20 out\n",
    "        # dropout layer on the second convolutional layer\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        # dense layers\n",
    "        self.fc1 = nn.Linear(320, 50)  # fc stands for fully-connected\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Like the activation function part of keras.\n",
    "        \"\"\"\n",
    "        # apply a 2-stride maxpooling onto our conv1, then relu it\n",
    "        x = F.relu(\n",
    "            F.max_pool2d(self.conv1(x), 2)\n",
    "        )\n",
    "        # now a 2-stride maxpooling onto the dropout of the conv2, then relu it\n",
    "        x = F.relu(\n",
    "            F.max_pool2d(\n",
    "                self.conv2_drop(self.conv2(x)), 2\n",
    "            )\n",
    "        )\n",
    "        # flatten the data for the linear layers, reshape to the fc1 sizing\n",
    "        x = x.view(-1, 320)\n",
    "        # activation on the first dense layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # use dropout ONLY IN TRAINING, this is extra\n",
    "        x = F.dropout(x, training=self.training)  # won't activate for evaluation, self.training is found in nn.Module\n",
    "        # activation for final dense layer\n",
    "        x = self.fc2(x)\n",
    "        # finally, output softmax to get probabilities\n",
    "        return F.softmax(x, dim=1)  # apply along rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c713fc-cb93-4f50-8ba8-e317b3465401",
   "metadata": {},
   "source": [
    "Now we can check if we can use a CUDA GPU or do we have to use the CPU, then port the model to this device. Then, we define the optimizer, loss function, our training regime and our testing regime:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a6cf11d-fe56-4156-9b6c-e98be12cc9f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check for GPU or CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "display(device)\n",
    "# port to either\n",
    "model = CNN().to(device)\n",
    "\n",
    "# define optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# define loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# training scheme per epoch\n",
    "def train(epoch):\n",
    "    # must tell model we are in training mode\n",
    "    model.train()\n",
    "    # iterate over batches in training data\n",
    "    for batch_idx, (data, target) in enumerate(loaders[\"train\"]):\n",
    "        # send to device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # zero out the gradients in the optimizer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # current model predictions\n",
    "        output = model(data)\n",
    "        # get loss from this\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()  # back-propagation\n",
    "        # then update gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        # every now and then document the epoch and loss stats\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(loaders['train'].dataset)} ({100.0 * batch_idx/len(loaders['train']):.0f}%)]\\t{loss.item():.6f}\")\n",
    "\n",
    "# testing scheme on evaluation/inference\n",
    "def test():\n",
    "    # tell model we are in testing mode\n",
    "    model.eval()\n",
    "    # set loss and number correct to zero\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    # dont want to calculate gradients as we are doing inference\n",
    "    with torch.no_grad():\n",
    "        for data, target in loaders[\"test\"]:\n",
    "            # send to device\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            # get predictions\n",
    "            output = model(data)\n",
    "            # update loss\n",
    "            test_loss += loss_fn(output, target).item()\n",
    "            \n",
    "            # get the models decision/prediction\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            # eq checks if they are equal, view the target in the same way as pred, sum over the whole batch\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    # have to get the average loss over all the batches\n",
    "    test_loss /= len(loaders[\"test\"].dataset)\n",
    "\n",
    "    # print stats\n",
    "    print(f\"\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(loaders['test'].dataset)} ({100.0 * correct/len(loaders['test'].dataset):.0f}%)\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2533fbb0-d3b8-4273-b397-ba356f874daa",
   "metadata": {},
   "source": [
    "Now start the training over as many epochs as we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1dbb959-eb20-47da-b25d-10377527ccae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\t2.303153\n",
      "Train Epoch: 1 [2000/60000 (3%)]\t2.285573\n",
      "Train Epoch: 1 [4000/60000 (7%)]\t2.188797\n",
      "Train Epoch: 1 [6000/60000 (10%)]\t1.926634\n",
      "Train Epoch: 1 [8000/60000 (13%)]\t1.832542\n",
      "Train Epoch: 1 [10000/60000 (17%)]\t1.858783\n",
      "Train Epoch: 1 [12000/60000 (20%)]\t1.795432\n",
      "Train Epoch: 1 [14000/60000 (23%)]\t1.762325\n",
      "Train Epoch: 1 [16000/60000 (27%)]\t1.739835\n",
      "Train Epoch: 1 [18000/60000 (30%)]\t1.744012\n",
      "Train Epoch: 1 [20000/60000 (33%)]\t1.728854\n",
      "Train Epoch: 1 [22000/60000 (37%)]\t1.642469\n",
      "Train Epoch: 1 [24000/60000 (40%)]\t1.643310\n",
      "Train Epoch: 1 [26000/60000 (43%)]\t1.734039\n",
      "Train Epoch: 1 [28000/60000 (47%)]\t1.652664\n",
      "Train Epoch: 1 [30000/60000 (50%)]\t1.607865\n",
      "Train Epoch: 1 [32000/60000 (53%)]\t1.640386\n",
      "Train Epoch: 1 [34000/60000 (57%)]\t1.659336\n",
      "Train Epoch: 1 [36000/60000 (60%)]\t1.606522\n",
      "Train Epoch: 1 [38000/60000 (63%)]\t1.671762\n",
      "Train Epoch: 1 [40000/60000 (67%)]\t1.628736\n",
      "Train Epoch: 1 [42000/60000 (70%)]\t1.646361\n",
      "Train Epoch: 1 [44000/60000 (73%)]\t1.652093\n",
      "Train Epoch: 1 [46000/60000 (77%)]\t1.612521\n",
      "Train Epoch: 1 [48000/60000 (80%)]\t1.669661\n",
      "Train Epoch: 1 [50000/60000 (83%)]\t1.597013\n",
      "Train Epoch: 1 [52000/60000 (87%)]\t1.521836\n",
      "Train Epoch: 1 [54000/60000 (90%)]\t1.574296\n",
      "Train Epoch: 1 [56000/60000 (93%)]\t1.594421\n",
      "Train Epoch: 1 [58000/60000 (97%)]\t1.606807\n",
      "\n",
      "Test set: Average loss: 0.0152, Accuracy: 9410/10000 (94%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\t1.579680\n",
      "Train Epoch: 2 [2000/60000 (3%)]\t1.579142\n",
      "Train Epoch: 2 [4000/60000 (7%)]\t1.623745\n",
      "Train Epoch: 2 [6000/60000 (10%)]\t1.580389\n",
      "Train Epoch: 2 [8000/60000 (13%)]\t1.534622\n",
      "Train Epoch: 2 [10000/60000 (17%)]\t1.580338\n",
      "Train Epoch: 2 [12000/60000 (20%)]\t1.581537\n",
      "Train Epoch: 2 [14000/60000 (23%)]\t1.601661\n",
      "Train Epoch: 2 [16000/60000 (27%)]\t1.552170\n",
      "Train Epoch: 2 [18000/60000 (30%)]\t1.595906\n",
      "Train Epoch: 2 [20000/60000 (33%)]\t1.567988\n",
      "Train Epoch: 2 [22000/60000 (37%)]\t1.554087\n",
      "Train Epoch: 2 [24000/60000 (40%)]\t1.580256\n",
      "Train Epoch: 2 [26000/60000 (43%)]\t1.564080\n",
      "Train Epoch: 2 [28000/60000 (47%)]\t1.563970\n",
      "Train Epoch: 2 [30000/60000 (50%)]\t1.584393\n",
      "Train Epoch: 2 [32000/60000 (53%)]\t1.612243\n",
      "Train Epoch: 2 [34000/60000 (57%)]\t1.593481\n",
      "Train Epoch: 2 [36000/60000 (60%)]\t1.551588\n",
      "Train Epoch: 2 [38000/60000 (63%)]\t1.513562\n",
      "Train Epoch: 2 [40000/60000 (67%)]\t1.546636\n",
      "Train Epoch: 2 [42000/60000 (70%)]\t1.557050\n",
      "Train Epoch: 2 [44000/60000 (73%)]\t1.594202\n",
      "Train Epoch: 2 [46000/60000 (77%)]\t1.531942\n",
      "Train Epoch: 2 [48000/60000 (80%)]\t1.568744\n",
      "Train Epoch: 2 [50000/60000 (83%)]\t1.578398\n",
      "Train Epoch: 2 [52000/60000 (87%)]\t1.568432\n",
      "Train Epoch: 2 [54000/60000 (90%)]\t1.532220\n",
      "Train Epoch: 2 [56000/60000 (93%)]\t1.542799\n",
      "Train Epoch: 2 [58000/60000 (97%)]\t1.553321\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy: 9583/10000 (96%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\t1.564389\n",
      "Train Epoch: 3 [2000/60000 (3%)]\t1.524244\n",
      "Train Epoch: 3 [4000/60000 (7%)]\t1.540704\n",
      "Train Epoch: 3 [6000/60000 (10%)]\t1.534858\n",
      "Train Epoch: 3 [8000/60000 (13%)]\t1.526859\n",
      "Train Epoch: 3 [10000/60000 (17%)]\t1.542607\n",
      "Train Epoch: 3 [12000/60000 (20%)]\t1.537042\n",
      "Train Epoch: 3 [14000/60000 (23%)]\t1.554440\n",
      "Train Epoch: 3 [16000/60000 (27%)]\t1.502032\n",
      "Train Epoch: 3 [18000/60000 (30%)]\t1.605639\n",
      "Train Epoch: 3 [20000/60000 (33%)]\t1.548946\n",
      "Train Epoch: 3 [22000/60000 (37%)]\t1.549270\n",
      "Train Epoch: 3 [24000/60000 (40%)]\t1.603438\n",
      "Train Epoch: 3 [26000/60000 (43%)]\t1.560485\n",
      "Train Epoch: 3 [28000/60000 (47%)]\t1.578847\n",
      "Train Epoch: 3 [30000/60000 (50%)]\t1.550479\n",
      "Train Epoch: 3 [32000/60000 (53%)]\t1.517223\n",
      "Train Epoch: 3 [34000/60000 (57%)]\t1.552256\n",
      "Train Epoch: 3 [36000/60000 (60%)]\t1.542408\n",
      "Train Epoch: 3 [38000/60000 (63%)]\t1.625630\n",
      "Train Epoch: 3 [40000/60000 (67%)]\t1.577850\n",
      "Train Epoch: 3 [42000/60000 (70%)]\t1.540395\n",
      "Train Epoch: 3 [44000/60000 (73%)]\t1.576760\n",
      "Train Epoch: 3 [46000/60000 (77%)]\t1.573700\n",
      "Train Epoch: 3 [48000/60000 (80%)]\t1.535025\n",
      "Train Epoch: 3 [50000/60000 (83%)]\t1.570987\n",
      "Train Epoch: 3 [52000/60000 (87%)]\t1.545370\n",
      "Train Epoch: 3 [54000/60000 (90%)]\t1.544366\n",
      "Train Epoch: 3 [56000/60000 (93%)]\t1.583726\n",
      "Train Epoch: 3 [58000/60000 (97%)]\t1.564965\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy: 9633/10000 (96%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\t1.527171\n",
      "Train Epoch: 4 [2000/60000 (3%)]\t1.505851\n",
      "Train Epoch: 4 [4000/60000 (7%)]\t1.513529\n",
      "Train Epoch: 4 [6000/60000 (10%)]\t1.546453\n",
      "Train Epoch: 4 [8000/60000 (13%)]\t1.551573\n",
      "Train Epoch: 4 [10000/60000 (17%)]\t1.540789\n",
      "Train Epoch: 4 [12000/60000 (20%)]\t1.561711\n",
      "Train Epoch: 4 [14000/60000 (23%)]\t1.529925\n",
      "Train Epoch: 4 [16000/60000 (27%)]\t1.585799\n",
      "Train Epoch: 4 [18000/60000 (30%)]\t1.574406\n",
      "Train Epoch: 4 [20000/60000 (33%)]\t1.520558\n",
      "Train Epoch: 4 [22000/60000 (37%)]\t1.526627\n",
      "Train Epoch: 4 [24000/60000 (40%)]\t1.579172\n",
      "Train Epoch: 4 [26000/60000 (43%)]\t1.573323\n",
      "Train Epoch: 4 [28000/60000 (47%)]\t1.625778\n",
      "Train Epoch: 4 [30000/60000 (50%)]\t1.545137\n",
      "Train Epoch: 4 [32000/60000 (53%)]\t1.549773\n",
      "Train Epoch: 4 [34000/60000 (57%)]\t1.584203\n",
      "Train Epoch: 4 [36000/60000 (60%)]\t1.534261\n",
      "Train Epoch: 4 [38000/60000 (63%)]\t1.519106\n",
      "Train Epoch: 4 [40000/60000 (67%)]\t1.560499\n",
      "Train Epoch: 4 [42000/60000 (70%)]\t1.547608\n",
      "Train Epoch: 4 [44000/60000 (73%)]\t1.532123\n",
      "Train Epoch: 4 [46000/60000 (77%)]\t1.539322\n",
      "Train Epoch: 4 [48000/60000 (80%)]\t1.538134\n",
      "Train Epoch: 4 [50000/60000 (83%)]\t1.527815\n",
      "Train Epoch: 4 [52000/60000 (87%)]\t1.530778\n",
      "Train Epoch: 4 [54000/60000 (90%)]\t1.554697\n",
      "Train Epoch: 4 [56000/60000 (93%)]\t1.565904\n",
      "Train Epoch: 4 [58000/60000 (97%)]\t1.582347\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 9673/10000 (97%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\t1.531768\n",
      "Train Epoch: 5 [2000/60000 (3%)]\t1.539861\n",
      "Train Epoch: 5 [4000/60000 (7%)]\t1.504002\n",
      "Train Epoch: 5 [6000/60000 (10%)]\t1.548096\n",
      "Train Epoch: 5 [8000/60000 (13%)]\t1.510809\n",
      "Train Epoch: 5 [10000/60000 (17%)]\t1.553219\n",
      "Train Epoch: 5 [12000/60000 (20%)]\t1.567112\n",
      "Train Epoch: 5 [14000/60000 (23%)]\t1.498412\n",
      "Train Epoch: 5 [16000/60000 (27%)]\t1.508505\n",
      "Train Epoch: 5 [18000/60000 (30%)]\t1.563477\n",
      "Train Epoch: 5 [20000/60000 (33%)]\t1.548771\n",
      "Train Epoch: 5 [22000/60000 (37%)]\t1.569040\n",
      "Train Epoch: 5 [24000/60000 (40%)]\t1.501768\n",
      "Train Epoch: 5 [26000/60000 (43%)]\t1.537894\n",
      "Train Epoch: 5 [28000/60000 (47%)]\t1.523542\n",
      "Train Epoch: 5 [30000/60000 (50%)]\t1.519240\n",
      "Train Epoch: 5 [32000/60000 (53%)]\t1.587771\n",
      "Train Epoch: 5 [34000/60000 (57%)]\t1.540617\n",
      "Train Epoch: 5 [36000/60000 (60%)]\t1.530070\n",
      "Train Epoch: 5 [38000/60000 (63%)]\t1.540565\n",
      "Train Epoch: 5 [40000/60000 (67%)]\t1.510005\n",
      "Train Epoch: 5 [42000/60000 (70%)]\t1.510580\n",
      "Train Epoch: 5 [44000/60000 (73%)]\t1.546023\n",
      "Train Epoch: 5 [46000/60000 (77%)]\t1.569633\n",
      "Train Epoch: 5 [48000/60000 (80%)]\t1.526497\n",
      "Train Epoch: 5 [50000/60000 (83%)]\t1.574557\n",
      "Train Epoch: 5 [52000/60000 (87%)]\t1.566685\n",
      "Train Epoch: 5 [54000/60000 (90%)]\t1.575001\n",
      "Train Epoch: 5 [56000/60000 (93%)]\t1.558579\n",
      "Train Epoch: 5 [58000/60000 (97%)]\t1.510271\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 9699/10000 (97%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\t1.582453\n",
      "Train Epoch: 6 [2000/60000 (3%)]\t1.533070\n",
      "Train Epoch: 6 [4000/60000 (7%)]\t1.545514\n",
      "Train Epoch: 6 [6000/60000 (10%)]\t1.516007\n",
      "Train Epoch: 6 [8000/60000 (13%)]\t1.548667\n",
      "Train Epoch: 6 [10000/60000 (17%)]\t1.536083\n",
      "Train Epoch: 6 [12000/60000 (20%)]\t1.533496\n",
      "Train Epoch: 6 [14000/60000 (23%)]\t1.554710\n",
      "Train Epoch: 6 [16000/60000 (27%)]\t1.537263\n",
      "Train Epoch: 6 [18000/60000 (30%)]\t1.496668\n",
      "Train Epoch: 6 [20000/60000 (33%)]\t1.543678\n",
      "Train Epoch: 6 [22000/60000 (37%)]\t1.534047\n",
      "Train Epoch: 6 [24000/60000 (40%)]\t1.548089\n",
      "Train Epoch: 6 [26000/60000 (43%)]\t1.534774\n",
      "Train Epoch: 6 [28000/60000 (47%)]\t1.532336\n",
      "Train Epoch: 6 [30000/60000 (50%)]\t1.544538\n",
      "Train Epoch: 6 [32000/60000 (53%)]\t1.521238\n",
      "Train Epoch: 6 [34000/60000 (57%)]\t1.543942\n",
      "Train Epoch: 6 [36000/60000 (60%)]\t1.550312\n",
      "Train Epoch: 6 [38000/60000 (63%)]\t1.518970\n",
      "Train Epoch: 6 [40000/60000 (67%)]\t1.512591\n",
      "Train Epoch: 6 [42000/60000 (70%)]\t1.541643\n",
      "Train Epoch: 6 [44000/60000 (73%)]\t1.538885\n",
      "Train Epoch: 6 [46000/60000 (77%)]\t1.519889\n",
      "Train Epoch: 6 [48000/60000 (80%)]\t1.553046\n",
      "Train Epoch: 6 [50000/60000 (83%)]\t1.540052\n",
      "Train Epoch: 6 [52000/60000 (87%)]\t1.521129\n",
      "Train Epoch: 6 [54000/60000 (90%)]\t1.514089\n",
      "Train Epoch: 6 [56000/60000 (93%)]\t1.554920\n",
      "Train Epoch: 6 [58000/60000 (97%)]\t1.516507\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 9722/10000 (97%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\t1.531161\n",
      "Train Epoch: 7 [2000/60000 (3%)]\t1.491748\n",
      "Train Epoch: 7 [4000/60000 (7%)]\t1.576292\n",
      "Train Epoch: 7 [6000/60000 (10%)]\t1.568748\n",
      "Train Epoch: 7 [8000/60000 (13%)]\t1.522341\n",
      "Train Epoch: 7 [10000/60000 (17%)]\t1.518987\n",
      "Train Epoch: 7 [12000/60000 (20%)]\t1.532275\n",
      "Train Epoch: 7 [14000/60000 (23%)]\t1.490020\n",
      "Train Epoch: 7 [16000/60000 (27%)]\t1.527779\n",
      "Train Epoch: 7 [18000/60000 (30%)]\t1.502572\n",
      "Train Epoch: 7 [20000/60000 (33%)]\t1.530671\n",
      "Train Epoch: 7 [22000/60000 (37%)]\t1.585065\n",
      "Train Epoch: 7 [24000/60000 (40%)]\t1.550618\n",
      "Train Epoch: 7 [26000/60000 (43%)]\t1.512859\n",
      "Train Epoch: 7 [28000/60000 (47%)]\t1.518803\n",
      "Train Epoch: 7 [30000/60000 (50%)]\t1.565876\n",
      "Train Epoch: 7 [32000/60000 (53%)]\t1.546798\n",
      "Train Epoch: 7 [34000/60000 (57%)]\t1.505494\n",
      "Train Epoch: 7 [36000/60000 (60%)]\t1.540593\n",
      "Train Epoch: 7 [38000/60000 (63%)]\t1.513570\n",
      "Train Epoch: 7 [40000/60000 (67%)]\t1.531420\n",
      "Train Epoch: 7 [42000/60000 (70%)]\t1.481070\n",
      "Train Epoch: 7 [44000/60000 (73%)]\t1.533738\n",
      "Train Epoch: 7 [46000/60000 (77%)]\t1.551231\n",
      "Train Epoch: 7 [48000/60000 (80%)]\t1.553641\n",
      "Train Epoch: 7 [50000/60000 (83%)]\t1.531489\n",
      "Train Epoch: 7 [52000/60000 (87%)]\t1.530166\n",
      "Train Epoch: 7 [54000/60000 (90%)]\t1.539119\n",
      "Train Epoch: 7 [56000/60000 (93%)]\t1.542577\n",
      "Train Epoch: 7 [58000/60000 (97%)]\t1.503171\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 9743/10000 (97%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\t1.511823\n",
      "Train Epoch: 8 [2000/60000 (3%)]\t1.542063\n",
      "Train Epoch: 8 [4000/60000 (7%)]\t1.550553\n",
      "Train Epoch: 8 [6000/60000 (10%)]\t1.520060\n",
      "Train Epoch: 8 [8000/60000 (13%)]\t1.501894\n",
      "Train Epoch: 8 [10000/60000 (17%)]\t1.506964\n",
      "Train Epoch: 8 [12000/60000 (20%)]\t1.553995\n",
      "Train Epoch: 8 [14000/60000 (23%)]\t1.577327\n",
      "Train Epoch: 8 [16000/60000 (27%)]\t1.516341\n",
      "Train Epoch: 8 [18000/60000 (30%)]\t1.497906\n",
      "Train Epoch: 8 [20000/60000 (33%)]\t1.483208\n",
      "Train Epoch: 8 [22000/60000 (37%)]\t1.533528\n",
      "Train Epoch: 8 [24000/60000 (40%)]\t1.547713\n",
      "Train Epoch: 8 [26000/60000 (43%)]\t1.521123\n",
      "Train Epoch: 8 [28000/60000 (47%)]\t1.529363\n",
      "Train Epoch: 8 [30000/60000 (50%)]\t1.528923\n",
      "Train Epoch: 8 [32000/60000 (53%)]\t1.511589\n",
      "Train Epoch: 8 [34000/60000 (57%)]\t1.557051\n",
      "Train Epoch: 8 [36000/60000 (60%)]\t1.526602\n",
      "Train Epoch: 8 [38000/60000 (63%)]\t1.504769\n",
      "Train Epoch: 8 [40000/60000 (67%)]\t1.587326\n",
      "Train Epoch: 8 [42000/60000 (70%)]\t1.554017\n",
      "Train Epoch: 8 [44000/60000 (73%)]\t1.509606\n",
      "Train Epoch: 8 [46000/60000 (77%)]\t1.496509\n",
      "Train Epoch: 8 [48000/60000 (80%)]\t1.552312\n",
      "Train Epoch: 8 [50000/60000 (83%)]\t1.506491\n",
      "Train Epoch: 8 [52000/60000 (87%)]\t1.535627\n",
      "Train Epoch: 8 [54000/60000 (90%)]\t1.496361\n",
      "Train Epoch: 8 [56000/60000 (93%)]\t1.499745\n",
      "Train Epoch: 8 [58000/60000 (97%)]\t1.531656\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 9748/10000 (97%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\t1.536295\n",
      "Train Epoch: 9 [2000/60000 (3%)]\t1.534955\n",
      "Train Epoch: 9 [4000/60000 (7%)]\t1.494497\n",
      "Train Epoch: 9 [6000/60000 (10%)]\t1.490616\n",
      "Train Epoch: 9 [8000/60000 (13%)]\t1.530259\n",
      "Train Epoch: 9 [10000/60000 (17%)]\t1.501828\n",
      "Train Epoch: 9 [12000/60000 (20%)]\t1.521567\n",
      "Train Epoch: 9 [14000/60000 (23%)]\t1.515648\n",
      "Train Epoch: 9 [16000/60000 (27%)]\t1.548293\n",
      "Train Epoch: 9 [18000/60000 (30%)]\t1.496259\n",
      "Train Epoch: 9 [20000/60000 (33%)]\t1.518765\n",
      "Train Epoch: 9 [22000/60000 (37%)]\t1.500122\n",
      "Train Epoch: 9 [24000/60000 (40%)]\t1.517991\n",
      "Train Epoch: 9 [26000/60000 (43%)]\t1.566744\n",
      "Train Epoch: 9 [28000/60000 (47%)]\t1.481375\n",
      "Train Epoch: 9 [30000/60000 (50%)]\t1.566161\n",
      "Train Epoch: 9 [32000/60000 (53%)]\t1.543130\n",
      "Train Epoch: 9 [34000/60000 (57%)]\t1.506400\n",
      "Train Epoch: 9 [36000/60000 (60%)]\t1.541036\n",
      "Train Epoch: 9 [38000/60000 (63%)]\t1.503476\n",
      "Train Epoch: 9 [40000/60000 (67%)]\t1.526615\n",
      "Train Epoch: 9 [42000/60000 (70%)]\t1.532061\n",
      "Train Epoch: 9 [44000/60000 (73%)]\t1.557330\n",
      "Train Epoch: 9 [46000/60000 (77%)]\t1.490914\n",
      "Train Epoch: 9 [48000/60000 (80%)]\t1.529349\n",
      "Train Epoch: 9 [50000/60000 (83%)]\t1.549266\n",
      "Train Epoch: 9 [52000/60000 (87%)]\t1.515314\n",
      "Train Epoch: 9 [54000/60000 (90%)]\t1.521695\n",
      "Train Epoch: 9 [56000/60000 (93%)]\t1.545840\n",
      "Train Epoch: 9 [58000/60000 (97%)]\t1.522810\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy: 9764/10000 (98%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\t1.516553\n",
      "Train Epoch: 10 [2000/60000 (3%)]\t1.534750\n",
      "Train Epoch: 10 [4000/60000 (7%)]\t1.519413\n",
      "Train Epoch: 10 [6000/60000 (10%)]\t1.488847\n",
      "Train Epoch: 10 [8000/60000 (13%)]\t1.505828\n",
      "Train Epoch: 10 [10000/60000 (17%)]\t1.525454\n",
      "Train Epoch: 10 [12000/60000 (20%)]\t1.525841\n",
      "Train Epoch: 10 [14000/60000 (23%)]\t1.511360\n",
      "Train Epoch: 10 [16000/60000 (27%)]\t1.547396\n",
      "Train Epoch: 10 [18000/60000 (30%)]\t1.486104\n",
      "Train Epoch: 10 [20000/60000 (33%)]\t1.543027\n",
      "Train Epoch: 10 [22000/60000 (37%)]\t1.496771\n",
      "Train Epoch: 10 [24000/60000 (40%)]\t1.542930\n",
      "Train Epoch: 10 [26000/60000 (43%)]\t1.542763\n",
      "Train Epoch: 10 [28000/60000 (47%)]\t1.491997\n",
      "Train Epoch: 10 [30000/60000 (50%)]\t1.513395\n",
      "Train Epoch: 10 [32000/60000 (53%)]\t1.520930\n",
      "Train Epoch: 10 [34000/60000 (57%)]\t1.544806\n",
      "Train Epoch: 10 [36000/60000 (60%)]\t1.522638\n",
      "Train Epoch: 10 [38000/60000 (63%)]\t1.550435\n",
      "Train Epoch: 10 [40000/60000 (67%)]\t1.540887\n",
      "Train Epoch: 10 [42000/60000 (70%)]\t1.540738\n",
      "Train Epoch: 10 [44000/60000 (73%)]\t1.496428\n",
      "Train Epoch: 10 [46000/60000 (77%)]\t1.511584\n",
      "Train Epoch: 10 [48000/60000 (80%)]\t1.514279\n",
      "Train Epoch: 10 [50000/60000 (83%)]\t1.568999\n",
      "Train Epoch: 10 [52000/60000 (87%)]\t1.511178\n",
      "Train Epoch: 10 [54000/60000 (90%)]\t1.494880\n",
      "Train Epoch: 10 [56000/60000 (93%)]\t1.559049\n",
      "Train Epoch: 10 [58000/60000 (97%)]\t1.504655\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy: 9774/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 11):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae5ab2f-7053-4650-9fd8-a52656dbb74d",
   "metadata": {},
   "source": [
    "Now lets see how it does on some of the test data ourselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e26400e6-7175-40b9-a649-f072506dff0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAJt0lEQVR4nO3dP2iVZx/H4fupsWA2lRJyUHHQUjo6nVBwCEUITiJUqAQMCpXOzg66t12lBbdooYNQIgjilJDNpXToHx0EIyouKjq0+LxL+b4V87499zHnPKa5LnAJz4/zE8P5eB/ibdO2bVsAoJTyXtcLAPDuEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFNiyTp06VZqm+Z+/7t+/3/WKMHaNu4/YqlZXV8udO3de+1rbtuXs2bNl//795eeff+5oM+jORNcLQFdmZmbKzMzMa19bXl4uL168KCdPnuxoK+iWj4/gbxYXF0vTNOXzzz/vehXohI+P4C9//PFHmZ6eLh999FFZXl7ueh3ohJMC/OXGjRvlyZMnPjpiSxMF+Mvi4mLZvn17+eyzz7peBTrj4yMopTx//rxMTU2V2dnZ8uOPP3a9DnTGSQFKKdeuXfNTR1CcFKCUUsrc3FxZXl4uDx8+LJOTk12vA51xUmDLe/z4cbl582Y5duyYILDliQJb3vfff1/+/PNPHx1B8fERlJmZmXL37t2ytrZWtm3b1vU60ClRACB8fARAiAIAIQoAhCgAEKIAQIgCADHw/7zWNM0o9wBgxAb5FwhOCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQEx0vQDdm5qaqp7p9/vVM4cPH66eGdbBgwerZ44ePVo989579X+vevXqVfXMsL788svqmUuXLo1gEzYLJwUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAomnbth3owaYZ9S78zf79+4eaO336dPXMF198UT2za9eu6plhv4cG/BZ9aw8ePKie6fV61TPj+v0Ma9++fdUza2trI9iEjTbI956TAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAEBMdL3AVnD+/PnqmWEuqSullKmpqaHmxuHy5ctDzX333XcbvMn6hrkQb3p6eiwzpZRy6dKl6plhLi48ceJE9czXX39dPcO7yUkBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIJq2bduBHmyaUe+yKVy7dq16Zm5urnpmYmK4uwoH/ON8zZUrV6pnrl+/PpbX4b8WFhaqZ7799tvqmadPn1bPzM/PV88sLS1Vz/B2Bnl/cFIAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQAiC19IV6/36+eWVlZGcEmbzp79uxQc8NcgMa/171796pn9uzZUz2zurpaPfPJJ59Uz/B2XIgHQBVRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAIiJrhfo0m+//VY9c+LEiRFs8qYffvhhLK/D5rF79+7qme3bt1fPDHhx8mtevXpVPcO7yUkBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAILb0hXhPnjypnnFRHV2ZnZ2tnvnggw9GsAn/Zk4KAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCALGlL8SDzeTMmTNjeZ21tbXqmePHj49gE7rgpABAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQLsSDMev3+0PNffrppxu8yfq++uqr6plHjx6NYBO64KQAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEC7EgzGbnp4eaq5t2w3eBN7kpABAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAuCUVxuzDDz/seoX/69ChQ12vQIecFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQCiadu2HejBphn1LrDp9Hq96plffvllqNfasWPHUHO1du7cWT3z7NmzEWzCRhvk7d5JAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACAmul4ANrPZ2dnqmcnJyRFssr6LFy9Wz7jcbmtzUgAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFACIpm3bdqAHm2bUu0Cner1e9cytW7eqZw4cOFA9U0opq6ur1TNHjhypnnn58mX1DJvDIG/3TgoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAMdH1AjAKe/furZ5ZWlqqnjl48GD1zE8//VQ9U0opCwsL1TMut6OWkwIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIA4ZZU3nm9Xq965sKFC9UzH3/8cfXMML755puh5n7//feNXQTW4aQAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEE3btu1ADzbNqHeBdfX7/eqZlZWVEWzypsXFxeqZ+fn5EWwC/2yQt3snBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYCY6HoB+CfT09PVMwPe8/jWbt++PZbXgXFxUgAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIF+IxNpOTk0PNnTt3boM3Wd+vv/5aPXP16tURbALdcVIAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAINySyti8//77Q83t2rVrgzdZ39LSUvXMgwcPRrAJdMdJAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACCatm3bgR5smlHvAsAIDfJ276QAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEBODPjjgvXkAbGJOCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAMR/ALbxRwnAyI7DAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set to evaluation mode\n",
    "model.eval()\n",
    "# get the data\n",
    "sample_idx = torch.randint(len(test_data), size=(1,)).item()\n",
    "data, target = test_data[sample_idx]\n",
    "data = data.unsqueeze(0).to(device)  # unsqueeze lets us send the same datapoint as a pretend batch\n",
    "# get the prediction\n",
    "output = model(data)\n",
    "prediction = output.argmax(dim=1, keepdim=True).item()\n",
    "# plot it\n",
    "img, label = test_data[sample_idx]\n",
    "plt.title(prediction)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81232ea4-1ff6-4d25-8e84-df0168882fa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
