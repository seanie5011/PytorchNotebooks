{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3f04f7b-cb2e-4e8f-ad26-3aba4b670d09",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning with Ray Tune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f64be9-f0b0-447b-a516-37dead2f65a3",
   "metadata": {},
   "source": [
    "In this notebook we use perform hyperparameter tuning using the Ray Tune library. [Ray Tune](https://docs.ray.io/en/latest/tune/index.html) is an industry standard tool for distributed hyperparameter tuning. We will integrate hyperparameter tuning into the problem of training a classifier on the CIFAR10 dataset.\n",
    "\n",
    "*Following the official tutorial: https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html*\n",
    "\n",
    "*Which is an extension of: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af25b72a-6868-4ef5-9a5d-0acab2f7d97b",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a359e433-1f00-46fb-bae6-cfb483dd7ad7",
   "metadata": {},
   "source": [
    "Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d3322d9-a3e6-4a2a-8250-8d6d993706ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seani\\Projects\\PytorchNotebooks\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-07-15 14:55:31,340\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-07-15 14:55:31,875\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "import os\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from ray import tune\n",
    "from ray import train\n",
    "from ray.train import Checkpoint, get_checkpoint\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "import ray.cloudpickle as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702fa8ab-e571-4666-88c7-4f7ed0ea729e",
   "metadata": {},
   "source": [
    "GPU setup if possible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "419799ae-e303-4c7f-923a-600e1e10241c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using: NVIDIA GeForce MX350\n"
     ]
    }
   ],
   "source": [
    "# set up device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "if device.type == 'cuda':\n",
    "    print(f'using: {torch.cuda.get_device_name(0) if device.type == \"cuda\" else f\"CPU with cores available: {os.cpu_count()}\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78acdd03-5f88-42ce-864d-c0b323b0599c",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cd537d-38d5-492a-824e-fa1c5e32ac4d",
   "metadata": {},
   "source": [
    "We wrap the data loaders in their own function and pass a global data directory. This way we can share a data directory between different trials.\n",
    "\n",
    "The data used is the CIFAR10 dataset, note that PyTorch will automatically download this data into the `data/` directory if it is not found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e3d202d-447a-42cd-885a-2bd5dfb7b02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir='data/'):\n",
    "    # turn into a tensor and then normalize it\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "    )\n",
    "\n",
    "    # get our datasets (will download if not found)\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "        root=data_dir, train=True, download=True, transform=transform\n",
    "    )\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root=data_dir, train=False, download=True, transform=transform\n",
    "    )\n",
    "\n",
    "    return trainset, testset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba951db-4dba-4c64-bf81-3b1064765ede",
   "metadata": {},
   "source": [
    "Lets also set where we want the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee71e025-1247-4399-84bc-1a4833d3e215",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.abspath('data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45383e25-aca9-4f46-9fbd-0b760e5a7d67",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b50c2d-b790-42b5-a659-323e92d3c3fb",
   "metadata": {},
   "source": [
    "We can only tune those parameters that are configurable. In this example, we can specify the layer sizes of the fully connected layers, given by `l1` and `l2` respectively. The network used consists ofconvolutional layers and max pooling layers before reaching a fully connected head:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ed833a4-8ecc-4508-aa73-71fc3bfc9827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, l1=120, l2=84):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)  # 5x5 kernel taking in 3 channels and outputting 6 channels\n",
    "        self.pool = nn.MaxPool2d(2, 2)  # max pooling with a 2x2 kernel and a stride of 2 (so no overlap but no gaps)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, l1)\n",
    "        self.fc2 = nn.Linear(l1, l2)\n",
    "        self.fc3 = nn.Linear(l2, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abe142d-1f73-4803-b42d-cfd272cb1967",
   "metadata": {},
   "source": [
    "## Setting up Ray Tune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d74228-8819-4407-93b4-165bd6884a45",
   "metadata": {},
   "source": [
    "Before we can take a look at training, let's first set our configurations for the hyperparameter tuning (define Ray Tune's search space). As an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bba165a2-b7db-4c79-a8ce-5e8c08c943c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': <ray.tune.search.sample.Categorical at 0x2114e1246d0>,\n",
       " 'l2': <ray.tune.search.sample.Categorical at 0x2114fd03750>,\n",
       " 'lr': <ray.tune.search.sample.Float at 0x2114dab1fd0>,\n",
       " 'batch_size': <ray.tune.search.sample.Categorical at 0x2114fd03e50>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "    \"l1\": tune.choice([2 ** i for i in range(9)]),\n",
    "    \"l2\": tune.choice([2 ** i for i in range(9)]),\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "    \"batch_size\": tune.choice([2, 4, 8, 16])\n",
    "}\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd821df-aa05-4b74-ac09-872937f70d74",
   "metadata": {},
   "source": [
    "The ``tune.choice()`` accepts a list of values that are uniformly sampled from. In this example, the ``l1`` and ``l2`` parameters should be powers of 2 between 4 and 256, so either 4, 8, 16, 32, 64, 128, or 256. The ``lr`` (learning rate) should be uniformly sampled between 0.0001 and 0.1. Lastly, the ``batch size`` is a choice between 2, 4, 8, and 16.\n",
    "\n",
    "At each trial, Ray Tune will now randomly sample a combination of parameters from these search spaces. It will then train a number of models in parallel and find the best performing one among these. We will also use the ``ASHAScheduler`` which will terminate bad performing trials early.\n",
    "\n",
    "Let's also set up the resources we will have access to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26d0407a-6c2d-400f-a493-245e526c14f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use half the available cpu cores, and use any gpus\n",
    "resources_per_trial = {\"cpu\": os.cpu_count() // 2, \"gpu\": torch.cuda.device_count()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06dc531-4aac-44a2-82d6-5fdcd1d2be09",
   "metadata": {},
   "source": [
    "The `num_samples` parameter is part of the configuration and can be used to sample our data multiple times instead of only once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1c4b2c3-7c86-4484-844b-d38b2328b9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f364bbaf-af82-4b36-8d15-055b4158b6e7",
   "metadata": {},
   "source": [
    "Defining our scheduler for the tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f93cc336-0f19-453d-afb0-289cb8e9c66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = ASHAScheduler(\n",
    "    metric=\"loss\",\n",
    "    mode=\"min\",\n",
    "    max_t=10,\n",
    "    grace_period=1,\n",
    "    reduction_factor=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26410ac-5f7b-4be2-ab45-01f0d4d53211",
   "metadata": {},
   "source": [
    "## Setting up Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f671c23f-d7e5-4fb4-9f49-b15d95628d6c",
   "metadata": {},
   "source": [
    "The full code for the training function is quite complex, as seen below.\n",
    "\n",
    "First we set up the network using the configuration, before loading the previous checkpoints state (if it exists). Then we load the data, where we have an 80/20 training/validation split. We then train the data for one epoch before finding its validation metrics, and recording this checkpoint. This is done for 10 epochs, with all metrics reported to Ray Tune throughout.\n",
    "\n",
    "Ray Tune can then use these metrics to decide which hyperparameter configuration lead to the best results. These metrics can also be used to stop bad performing trials early in order to avoid wasting resources on those trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf4e2f72-69d5-4d5d-a5c9-51b8179dcdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cifar(config, device=\"cpu\", data_dir=None):\n",
    "    # set up network on device using configuration, along with parameters\n",
    "    net = Net(config[\"l1\"], config[\"l2\"])\n",
    "    net.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=config[\"lr\"], momentum=0.9)\n",
    "\n",
    "    # if we have a checkpoint, then load it\n",
    "    checkpoint = get_checkpoint()\n",
    "    if checkpoint:\n",
    "        with checkpoint.as_directory() as checkpoint_dir:\n",
    "            data_path = Path(checkpoint_dir) / \"data.pkl\"\n",
    "            with open(data_path, \"rb\") as fp:\n",
    "                checkpoint_state = pickle.load(fp)\n",
    "            start_epoch = checkpoint_state[\"epoch\"]\n",
    "            net.load_state_dict(checkpoint_state[\"net_state_dict\"])\n",
    "            optimizer.load_state_dict(checkpoint_state[\"optimizer_state_dict\"])\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "\n",
    "    # load the data and split into training and validation\n",
    "    trainset, testset = load_data(data_dir)\n",
    "\n",
    "    train_val_split = int(len(trainset) * 0.8)  # 80/20 split\n",
    "    train_subset, val_subset = random_split(\n",
    "        trainset, [train_val_split, len(trainset) - train_val_split]\n",
    "    )\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        train_subset, batch_size=int(config[\"batch_size\"]), shuffle=True, num_workers=0\n",
    "    )\n",
    "    valloader = torch.utils.data.DataLoader(\n",
    "        val_subset, batch_size=int(config[\"batch_size\"]), shuffle=True, num_workers=0\n",
    "    )\n",
    "\n",
    "    # train for 10 epochs total\n",
    "    for epoch in range(start_epoch, 10):\n",
    "        # train this epoch\n",
    "        running_loss = 0.0\n",
    "        epoch_steps = 0\n",
    "        for i, data in enumerate(trainloader):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            epoch_steps += 1\n",
    "            if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "                print(\n",
    "                    \"[%d, %5d] loss: %.3f\"\n",
    "                    % (epoch + 1, i + 1, running_loss / epoch_steps)\n",
    "                )\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # get the validation metrics\n",
    "        val_loss = 0.0\n",
    "        val_steps = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for i, data in enumerate(valloader):\n",
    "            with torch.no_grad():\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = net(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.cpu().numpy()\n",
    "                val_steps += 1\n",
    "\n",
    "        # save a checkpoint of our current epoch and network state\n",
    "        checkpoint_data = {\n",
    "            \"epoch\": epoch,\n",
    "            \"net_state_dict\": net.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        }\n",
    "        with tempfile.TemporaryDirectory() as checkpoint_dir:\n",
    "            data_path = Path(checkpoint_dir) / \"data.pkl\"\n",
    "            with open(data_path, \"wb\") as fp:\n",
    "                pickle.dump(checkpoint_data, fp)\n",
    "\n",
    "            checkpoint = Checkpoint.from_directory(checkpoint_dir)\n",
    "            # tell raytune how we performed\n",
    "            train.report(\n",
    "                {\"loss\": val_loss / val_steps, \"accuracy\": correct / total},\n",
    "                checkpoint=checkpoint,\n",
    "            )\n",
    "\n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68113424-b819-4d6b-8453-b8f5b656b36b",
   "metadata": {},
   "source": [
    "Ee also use a hold-out test set with data that has not been used for training the model, lets wrap this in a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "553003be-6822-4829-b16b-e587aeeebeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(net, device=\"cpu\"):\n",
    "    # load testing data\n",
    "    trainset, testset = load_data()\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=4, shuffle=False, num_workers=0\n",
    "    )\n",
    "\n",
    "    # evaluate the model\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911a9322-2bae-4bd8-b7c1-3c7ac418a162",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c312878a-dbd5-4786-9d6d-f943c5295aab",
   "metadata": {},
   "source": [
    "Now we can finally start the tuning.\n",
    "\n",
    "We wrap the ``train_cifar`` function with ``functools.partial`` to set our parameters. We can also tell Ray Tune what resources should be available for each trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7af80818-791c-4189-9fa8-1f27311d3c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-15 14:57:45,427\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-07-15 15:49:30</td></tr>\n",
       "<tr><td>Running for: </td><td>00:51:44.93        </td></tr>\n",
       "<tr><td>Memory:      </td><td>6.7/11.7 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=10<br>Bracket: Iter 8.000: -1.3567131178379057 | Iter 4.000: -1.6016627616882324 | Iter 2.000: -1.6883984395980836 | Iter 1.000: -1.9781187180042266<br>Logical resource usage: 4.0/8 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  l1</th><th style=\"text-align: right;\">  l2</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_cifar_d4897_00000</td><td>TERMINATED</td><td>127.0.0.1:8112 </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\"> 256</td><td style=\"text-align: right;\">   2</td><td style=\"text-align: right;\">0.00829845 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">        815.185 </td><td style=\"text-align: right;\">2.30639</td><td style=\"text-align: right;\">    0.1   </td></tr>\n",
       "<tr><td>train_cifar_d4897_00001</td><td>TERMINATED</td><td>127.0.0.1:14188</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">   2</td><td style=\"text-align: right;\">  32</td><td style=\"text-align: right;\">0.0491035  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        104.856 </td><td style=\"text-align: right;\">2.32841</td><td style=\"text-align: right;\">    0.098 </td></tr>\n",
       "<tr><td>train_cifar_d4897_00002</td><td>TERMINATED</td><td>127.0.0.1:17588</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\"> 128</td><td style=\"text-align: right;\">  64</td><td style=\"text-align: right;\">0.00260339 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">        477.295 </td><td style=\"text-align: right;\">1.09617</td><td style=\"text-align: right;\">    0.6222</td></tr>\n",
       "<tr><td>train_cifar_d4897_00003</td><td>TERMINATED</td><td>127.0.0.1:3472 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">   2</td><td style=\"text-align: right;\">   4</td><td style=\"text-align: right;\">0.00540818 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">        382.508 </td><td style=\"text-align: right;\">1.59017</td><td style=\"text-align: right;\">    0.3832</td></tr>\n",
       "<tr><td>train_cifar_d4897_00004</td><td>TERMINATED</td><td>127.0.0.1:12132</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\"> 128</td><td style=\"text-align: right;\">   2</td><td style=\"text-align: right;\">0.000200899</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        114.262 </td><td style=\"text-align: right;\">2.30472</td><td style=\"text-align: right;\">    0.102 </td></tr>\n",
       "<tr><td>train_cifar_d4897_00005</td><td>TERMINATED</td><td>127.0.0.1:15960</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">0.00254347 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        249.805 </td><td style=\"text-align: right;\">1.89697</td><td style=\"text-align: right;\">    0.1902</td></tr>\n",
       "<tr><td>train_cifar_d4897_00006</td><td>TERMINATED</td><td>127.0.0.1:8296 </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">0.0353829  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        189.712 </td><td style=\"text-align: right;\">2.33851</td><td style=\"text-align: right;\">    0.1002</td></tr>\n",
       "<tr><td>train_cifar_d4897_00007</td><td>TERMINATED</td><td>127.0.0.1:8272 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">   4</td><td style=\"text-align: right;\">  16</td><td style=\"text-align: right;\">0.0951171  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         31.1576</td><td style=\"text-align: right;\">2.35162</td><td style=\"text-align: right;\">    0.0978</td></tr>\n",
       "<tr><td>train_cifar_d4897_00008</td><td>TERMINATED</td><td>127.0.0.1:1296 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">   8</td><td style=\"text-align: right;\">   2</td><td style=\"text-align: right;\">0.00957997 </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        205.509 </td><td style=\"text-align: right;\">1.63253</td><td style=\"text-align: right;\">    0.3348</td></tr>\n",
       "<tr><td>train_cifar_d4897_00009</td><td>TERMINATED</td><td>127.0.0.1:16976</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">  64</td><td style=\"text-align: right;\">  64</td><td style=\"text-align: right;\">0.00202307 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">        403.011 </td><td style=\"text-align: right;\">1.12562</td><td style=\"text-align: right;\">    0.6052</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">   loss</th><th>should_checkpoint  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_cifar_d4897_00000</td><td style=\"text-align: right;\">    0.1   </td><td style=\"text-align: right;\">2.30639</td><td>True               </td></tr>\n",
       "<tr><td>train_cifar_d4897_00001</td><td style=\"text-align: right;\">    0.098 </td><td style=\"text-align: right;\">2.32841</td><td>True               </td></tr>\n",
       "<tr><td>train_cifar_d4897_00002</td><td style=\"text-align: right;\">    0.6222</td><td style=\"text-align: right;\">1.09617</td><td>True               </td></tr>\n",
       "<tr><td>train_cifar_d4897_00003</td><td style=\"text-align: right;\">    0.3832</td><td style=\"text-align: right;\">1.59017</td><td>True               </td></tr>\n",
       "<tr><td>train_cifar_d4897_00004</td><td style=\"text-align: right;\">    0.102 </td><td style=\"text-align: right;\">2.30472</td><td>True               </td></tr>\n",
       "<tr><td>train_cifar_d4897_00005</td><td style=\"text-align: right;\">    0.1902</td><td style=\"text-align: right;\">1.89697</td><td>True               </td></tr>\n",
       "<tr><td>train_cifar_d4897_00006</td><td style=\"text-align: right;\">    0.1002</td><td style=\"text-align: right;\">2.33851</td><td>True               </td></tr>\n",
       "<tr><td>train_cifar_d4897_00007</td><td style=\"text-align: right;\">    0.0978</td><td style=\"text-align: right;\">2.35162</td><td>True               </td></tr>\n",
       "<tr><td>train_cifar_d4897_00008</td><td style=\"text-align: right;\">    0.3348</td><td style=\"text-align: right;\">1.63253</td><td>True               </td></tr>\n",
       "<tr><td>train_cifar_d4897_00009</td><td style=\"text-align: right;\">    0.6052</td><td style=\"text-align: right;\">1.12562</td><td>True               </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-15 15:49:30,424\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to 'C:/Users/seani/ray_results/train_cifar_2024-07-15_14-57-45' in 0.0289s.\n",
      "2024-07-15 15:49:30,439\tINFO tune.py:1041 -- Total run time: 3105.01 seconds (3104.90 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'l1': 128, 'l2': 64, 'lr': 0.0026033864414838764, 'batch_size': 16}\n",
      "Best trial final validation loss: 1.0961708369731904\n",
      "Best trial final validation accuracy: 0.6222\n"
     ]
    }
   ],
   "source": [
    "result = tune.run(\n",
    "    partial(train_cifar, data_dir=data_dir, device=device),\n",
    "    resources_per_trial=resources_per_trial,\n",
    "    config=config,\n",
    "    num_samples=num_samples,\n",
    "    scheduler=scheduler\n",
    ")\n",
    "\n",
    "best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "print(f\"Best trial config: {best_trial.config}\")\n",
    "print(f\"Best trial final validation loss: {best_trial.last_result['loss']}\")\n",
    "print(f\"Best trial final validation accuracy: {best_trial.last_result['accuracy']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e980f8-dc71-4f71-ad4b-cc6f7989e774",
   "metadata": {},
   "source": [
    "Now lets get our best trial model and evaluate on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a94c60c0-897a-4774-b984-3542bd238173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Best trial test set accuracy: 0.6119\n"
     ]
    }
   ],
   "source": [
    "# get the model\n",
    "best_trained_model = Net(best_trial.config[\"l1\"], best_trial.config[\"l2\"])\n",
    "best_trained_model.to(device)\n",
    "\n",
    "# get its checkpoint so we can load the state\n",
    "best_checkpoint = result.get_best_checkpoint(trial=best_trial, metric=\"accuracy\", mode=\"max\")\n",
    "with best_checkpoint.as_directory() as checkpoint_dir:\n",
    "    data_path = Path(checkpoint_dir) / \"data.pkl\"\n",
    "    with open(data_path, \"rb\") as fp:\n",
    "        best_checkpoint_data = pickle.load(fp)\n",
    "\n",
    "    best_trained_model.load_state_dict(best_checkpoint_data[\"net_state_dict\"])\n",
    "\n",
    "    # with the loaded state we can then get the test accuracy\n",
    "    test_acc = test_accuracy(best_trained_model, device)\n",
    "    print(\"Best trial test set accuracy: {}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99860426-1f28-4181-9df7-013ebcf9d902",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
